{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the configuration of the low-fidelity model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# get the accuracy metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from mfbml.methods.mf_dnn_bnn import MFDNNBNN\n",
    "from mfbml.methods.bnn import BNNWrapper\n",
    "from mfbml.methods.sequential_mf_bnn import SequentialMFBNN\n",
    "from mfbml.problems.high_dimension_problems import MengCase1\n",
    "from mfbml.metrics import (\n",
    "    mean_log_likelihood_value,\n",
    "    normalized_mae,\n",
    "    normalized_rmse,\n",
    ")\n",
    "\n",
    "# fix the random seed for reproducibility\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "func = MengCase1(noise_std=0.05)\n",
    "\n",
    "# generate samples (21 HF samples, 201 LF samples)\n",
    "lf_samples = torch.linspace(0, 1, 201).reshape(-1, 1)\n",
    "hf_samples = lf_samples[::10]  # sample every 5 points\n",
    "\n",
    "# generate responses\n",
    "lf_responses = func.lf(lf_samples)\n",
    "hf_responses = func.hf(hf_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the test points\n",
    "test_samples = torch.linspace(0, 1, 1001).reshape(-1, 1)\n",
    "# noiseless responses\n",
    "test_hf_responses_noiseless = func.hf(test_samples, noise_hf=0.0)\n",
    "test_lf_responses_noiseless = func.lf(test_samples, noise_lf=0.0)\n",
    "\n",
    "# noise responses\n",
    "test_hf_responses = func.hf(test_samples)\n",
    "test_lf_responses = func.lf(test_samples)\n",
    "\n",
    "# plot the function\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(test_samples, test_hf_responses_noiseless, label=\"HF\")\n",
    "ax.plot(test_samples, test_lf_responses_noiseless, label=\"LF\")\n",
    "# plot test noisy responses\n",
    "ax.scatter(test_samples, test_hf_responses, label=\"HF noise responses\")\n",
    "ax.scatter(test_samples, test_lf_responses, label=\"LF noise responses\")\n",
    "# plot the samples\n",
    "ax.scatter(hf_samples, hf_responses, label=\"HF samples\")\n",
    "ax.scatter(lf_samples, lf_responses, label=\"LF samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lf_responses_noiseless.flatten().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the person correlation coefficient via the noiseless responses\n",
    "rho, pval = pearsonr(\n",
    "    test_hf_responses_noiseless.flatten().numpy().tolist(),\n",
    "    test_lf_responses_noiseless.flatten().numpy().tolist(),\n",
    ")\n",
    "print(\"rho: \", rho)\n",
    "print(\"pval: \", pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for DNN and BNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the configuration of the low-fidelity model\n",
    "lf_configure = {\n",
    "    \"in_features\": 1,\n",
    "    \"hidden_features\": [20, 20],\n",
    "    \"out_features\": 1,\n",
    "    \"activation\": \"Tanh\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.000001,\n",
    "    \"loss\": \"mse\",\n",
    "}\n",
    "# create the configuration of the high-fidelity model\n",
    "hf_parallel_configure = {\n",
    "    \"in_features\": 1,\n",
    "    \"hidden_features\": [50, 50],\n",
    "    \"out_features\": 1,\n",
    "    \"activation\": \"Tanh\",\n",
    "    \"lr\": 0.001,\n",
    "    \"sigma\": 0.05,\n",
    "}\n",
    "#\n",
    "hf_sequential_configure = {\n",
    "    \"in_features\": 2,\n",
    "    \"hidden_features\": [50, 50],\n",
    "    \"out_features\": 1,\n",
    "    \"activation\": \"Tanh\",\n",
    "    \"lr\": 0.001,\n",
    "    \"sigma\": 0.05,\n",
    "}\n",
    "\n",
    "# training configure\n",
    "samples = {\"lf\": lf_samples, \"hf\": hf_samples}\n",
    "\n",
    "responses = {\"lf\": lf_responses, \"hf\": hf_responses}\n",
    "\n",
    "# lf train config\n",
    "lf_train_config = {\n",
    "    \"batch_size\": None,\n",
    "    \"num_epochs\": 10000,\n",
    "    \"print_iter\": 100,\n",
    "    \"data_split\": False,\n",
    "}\n",
    "hf_train_config = {\n",
    "    \"num_epochs\": 20000,\n",
    "    \"sample_freq\": 100,\n",
    "    \"print_info\": True,\n",
    "    \"burn_in_epochs\": 10000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train standard BNN using HF data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define BNN\n",
    "bnn_model = BNNWrapper(\n",
    "    in_features=1,\n",
    "    hidden_features=[50, 50],\n",
    "    out_features=1,\n",
    "    activation=\"Tanh\",\n",
    "    lr=0.001,\n",
    "    sigma=0.05,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "bnn_model.train(\n",
    "    x=hf_samples,\n",
    "    y=hf_responses,\n",
    "    num_epochs=20000,\n",
    "    sample_freq=100,\n",
    "    burn_in_epochs=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the posterior of bnn\n",
    "bnn_y, bnn_epistemic, bnn_total_unc, bnn_aleatoric = bnn_model.predict(x=test_samples)\n",
    "\n",
    "# plot\n",
    "plt.figure()\n",
    "plt.plot(hf_samples, hf_responses, \"o\", label=\"hf\")\n",
    "plt.plot(test_samples.numpy(), bnn_y, label=\"hf prediction\")\n",
    "plt.plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    label=\"hf ground truth\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    test_samples.flatten().numpy(),\n",
    "    (bnn_y - 2 * bnn_total_unc).reshape(-1),\n",
    "    (bnn_y + 2 * bnn_total_unc).reshape(-1),\n",
    "    alpha=0.5,\n",
    "    label=\"uncertainty\",\n",
    ")\n",
    "plt.legend()\n",
    "# plt.savefig(\"bnn.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training of sequential MF-DNN-BNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential mf-bnn\n",
    "sequential_bnn = SequentialMFBNN(\n",
    "    design_space=torch.Tensor([[0, 1]]),\n",
    "    lf_configure=lf_configure,\n",
    "    hf_configure=hf_sequential_configure,\n",
    ")\n",
    "# train the model\n",
    "sequential_bnn.train(\n",
    "    samples=samples,\n",
    "    responses=responses,\n",
    "    lf_train_config=lf_train_config,\n",
    "    hf_train_config=hf_train_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the posterior of sequential mf-bnn\n",
    "(\n",
    "    sequential_bnn_y,\n",
    "    sequential_bnn_epistemic,\n",
    "    sequential_bnn_total_unc,\n",
    "    sequential_bnn_aleatoric,\n",
    ") = sequential_bnn.predict(x=test_samples)\n",
    "# get lf predictions\n",
    "sequential_bnn_lf_y = sequential_bnn.predict_lf(x=test_samples)\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hf_samples, hf_responses, \"o\", label=\"hf\")\n",
    "ax.plot(test_samples.numpy(), sequential_bnn_y, label=\"hf prediction\")\n",
    "ax.plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    label=\"hf ground truth\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    test_samples.flatten().numpy(),\n",
    "    (sequential_bnn_y - 2 * sequential_bnn_total_unc).reshape(-1),\n",
    "    (sequential_bnn_y + 2 * sequential_bnn_total_unc).reshape(-1),\n",
    "    alpha=0.5,\n",
    "    label=\"uncertainty\",\n",
    ")\n",
    "# plot lf samples\n",
    "ax.scatter(lf_samples, lf_responses, label=\"LF samples\")\n",
    "ax.plot(\n",
    "    test_samples.numpy(), sequential_bnn_lf_y.detach().numpy(), label=\"LF prediction\"\n",
    ")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6900 train loss:  0.004036199301481247\n",
      "epoch:  7000 train loss:  0.004034875426441431\n"
     ]
    }
   ],
   "source": [
    "# create the MFDNNBNN object\n",
    "mfdnnbnn = MFDNNBNN(\n",
    "    design_space=torch.Tensor([[0, 1]]),\n",
    "    lf_configure=lf_configure,\n",
    "    hf_configure=hf_parallel_configure,\n",
    "    beta_optimize=False,\n",
    "    beta_bounds=[-5, 5],\n",
    ")\n",
    "# define beta\n",
    "mfdnnbnn.beta = np.array([2.0])\n",
    "mfdnnbnn.train(\n",
    "    samples=samples,\n",
    "    responses=responses,\n",
    "    lf_train_config=lf_train_config,\n",
    "    hf_train_config=hf_train_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the MFDNNBNN object\n",
    "(\n",
    "    y_proposed,\n",
    "    epistemic_proposed,\n",
    "    total_unc_proposed,\n",
    "    aleatoric_proposed,\n",
    ") = mfdnnbnn.predict(x=test_samples)\n",
    "# lf prediction\n",
    "lf_y_proposed = mfdnnbnn.predict_lf(test_samples)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(hf_samples, hf_responses, \"o\", label=\"hf\")\n",
    "ax.plot(test_samples.numpy(), y_proposed, label=\"hf prediction\")\n",
    "ax.plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    label=\"hf ground truth\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    test_samples.flatten().numpy(),\n",
    "    (y_proposed - 2 * total_unc_proposed).reshape(-1),\n",
    "    (y_proposed + 2 * total_unc_proposed).reshape(-1),\n",
    "    alpha=0.5,\n",
    "    label=\"uncertainty\",\n",
    ")\n",
    "# plot lf samples\n",
    "ax.scatter(lf_samples, lf_responses, label=\"LF samples\")\n",
    "ax.plot(test_samples.numpy(), lf_y_proposed.detach().numpy(), label=\"LF prediction\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=====================================\")\n",
    "print(\"BNN\")\n",
    "nrmse_bnn = normalized_rmse(test_hf_responses_noiseless.numpy(), bnn_y)\n",
    "print(\"nrmse: \", nrmse_bnn)\n",
    "nmae_bnn = normalized_mae(test_hf_responses_noiseless.numpy(), bnn_y)\n",
    "print(\"nmae: \", nmae_bnn)\n",
    "ll_bnn = mean_log_likelihood_value(test_hf_responses.numpy(), bnn_y, bnn_total_unc)\n",
    "print(\"ll_bnn: \", ll_bnn)\n",
    "# r2 score\n",
    "print(\"=====================================\")\n",
    "print(\"R2 Score\")\n",
    "print(\"BNN: \", r2_score(test_hf_responses_noiseless.numpy(), bnn_y))\n",
    "# sequential mf-bnn\n",
    "print(\"=====================================\")\n",
    "print(\"Sequential MF-BNN\")\n",
    "nrmse_sequential_bnn = normalized_rmse(\n",
    "    test_hf_responses_noiseless.numpy(), sequential_bnn_y\n",
    ")\n",
    "print(\"nrmse: \", nrmse_sequential_bnn)\n",
    "nmae_sequential_bnn = normalized_mae(\n",
    "    test_hf_responses_noiseless.numpy(), sequential_bnn_y\n",
    ")\n",
    "print(\"nmae: \", nmae_sequential_bnn)\n",
    "ll_sequential_bnn = mean_log_likelihood_value(\n",
    "    test_hf_responses.numpy(),\n",
    "    sequential_bnn_y,\n",
    "    sequential_bnn_total_unc,\n",
    ")\n",
    "print(\"ll_sequential_bnn: \", ll_sequential_bnn)\n",
    "# R2 Score\n",
    "print(\"=====================================\")\n",
    "print(\"R2 Score\")\n",
    "print(\"BNN: \", r2_score(test_hf_responses_noiseless.numpy(), sequential_bnn_y))\n",
    "# MFDNNBNN\n",
    "print(\"=====================================\")\n",
    "print(\"MFDNNBNN\")\n",
    "nrmse_mfdnnbnn = normalized_rmse(test_hf_responses_noiseless.numpy(), y_proposed)\n",
    "print(\"nrmse: \", nrmse_mfdnnbnn)\n",
    "nmae_mfdnnbnn = normalized_mae(test_hf_responses_noiseless.numpy(), y_proposed)\n",
    "print(\"nmae: \", nmae_mfdnnbnn)\n",
    "ll_mfdnnbnn = mean_log_likelihood_value(\n",
    "    test_hf_responses.numpy(), y_proposed, total_unc_proposed\n",
    ")\n",
    "print(\"ll_mfdnnbnn: \", ll_mfdnnbnn)\n",
    "# R2 Score\n",
    "print(\"=====================================\")\n",
    "print(\"R2 Score\")\n",
    "print(\"BNN: \", r2_score(test_hf_responses_noiseless.numpy(), y_proposed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_size = 12\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# plot results of bnn\n",
    "ax[0].plot(\n",
    "    samples[\"hf\"].numpy(),\n",
    "    responses[\"hf\"].numpy(),\n",
    "    \"kx\",\n",
    "    linewidth=2,\n",
    "    markersize=10,\n",
    "    label=\"HF samples\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    \"--\",\n",
    "    color=\"#33BBEE\",\n",
    "    linewidth=2,\n",
    "    label=\"HF truth\",\n",
    ")\n",
    "ax[0].plot(\n",
    "    test_samples.numpy(),\n",
    "    bnn_y,\n",
    "    \"-\",\n",
    "    color=\"#CC3311\",\n",
    "    linewidth=2,\n",
    "    label=\"HF prediction\",\n",
    ")\n",
    "ax[0].fill_between(\n",
    "    test_samples.flatten(),\n",
    "    (bnn_y - 2 * bnn_total_unc).flatten(),\n",
    "    (bnn_y + 2 * bnn_total_unc).flatten(),\n",
    "    alpha=0.5,\n",
    "    color=\"#BBBBBB\",\n",
    "    label=\"CI interval\",\n",
    ")\n",
    "ax[0].legend(loc=\"lower right\")\n",
    "ax[0].set_title(\"BNN\", fontsize=font_size)\n",
    "ax[0].set_xlabel(\"x\", fontsize=font_size)\n",
    "ax[0].set_ylabel(\"y\", fontsize=font_size)\n",
    "ax[0].tick_params(labelsize=font_size)\n",
    "ax[0].set_ylim([-2, 1.0])\n",
    "\n",
    "#  plot for sequential mf-bnn\n",
    "ax[1].plot(\n",
    "    samples[\"hf\"].numpy(),\n",
    "    responses[\"hf\"].numpy(),\n",
    "    \"kx\",\n",
    "    linewidth=2,\n",
    "    markersize=10,\n",
    "    label=\"HF samples\",\n",
    ")\n",
    "ax[1].plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    \"--\",\n",
    "    color=\"#33BBEE\",\n",
    "    linewidth=2,\n",
    "    label=\"HF noiseless truth\",\n",
    ")\n",
    "ax[1].plot(\n",
    "    test_samples.numpy(),\n",
    "    sequential_bnn_y,\n",
    "    \"-\",\n",
    "    color=\"#CC3311\",\n",
    "    linewidth=2,\n",
    "    label=\"HF prediction\",\n",
    ")\n",
    "\n",
    "ax[1].fill_between(\n",
    "    test_samples.flatten().numpy(),\n",
    "    (sequential_bnn_y - 2 * sequential_bnn_total_unc).flatten(),\n",
    "    (sequential_bnn_y + 2 * sequential_bnn_total_unc).flatten(),\n",
    "    alpha=0.5,\n",
    "    color=\"#BBBBBB\",\n",
    "    label=\"CI interval\",\n",
    ")\n",
    "ax[1].legend(loc=\"lower right\")\n",
    "ax[1].set_title(\"Meng's MF-BNN\", fontsize=font_size)\n",
    "ax[1].set_xlabel(\"x\", fontsize=font_size)\n",
    "ax[1].set_ylabel(\" \", fontsize=font_size)\n",
    "ax[1].tick_params(labelsize=font_size)\n",
    "ax[1].set_ylim([-2, 1.0])\n",
    "\n",
    "# plot for MFDNNBNN\n",
    "ax[2].plot(\n",
    "    samples[\"hf\"].numpy(),\n",
    "    responses[\"hf\"].numpy(),\n",
    "    \"kx\",\n",
    "    linewidth=2,\n",
    "    markersize=10,\n",
    "    label=\"HF samples\",\n",
    ")\n",
    "ax[2].plot(\n",
    "    test_samples.numpy(),\n",
    "    test_hf_responses_noiseless.numpy(),\n",
    "    \"--\",\n",
    "    color=\"#33BBEE\",\n",
    "    linewidth=2,\n",
    "    label=\"HF truth\",\n",
    ")\n",
    "ax[2].plot(\n",
    "    test_samples.numpy(),\n",
    "    y_proposed,\n",
    "    \"-\",\n",
    "    color=\"#CC3311\",\n",
    "    linewidth=2,\n",
    "    label=\"HF prediction\",\n",
    ")\n",
    "\n",
    "ax[2].fill_between(\n",
    "    test_samples.flatten().numpy(),\n",
    "    (y_proposed - 2 * total_unc_proposed).flatten(),\n",
    "    (y_proposed + 2 * total_unc_proposed).flatten(),\n",
    "    alpha=0.5,\n",
    "    color=\"#BBBBBB\",\n",
    "    label=\"CI interval\",\n",
    ")\n",
    "\n",
    "ax[2].set_title(\"MF-DNN-BNN\", fontsize=font_size)\n",
    "ax[2].set_xlabel(\"x\", fontsize=font_size)\n",
    "ax[2].set_ylabel(\" \", fontsize=font_size)\n",
    "ax[2].tick_params(labelsize=font_size)\n",
    "ax[2].set_ylim([-2, 1.0])\n",
    "ax[2].legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error plot\n",
    "fig, ax = plt.subplots(1, figsize=(6, 4))\n",
    "# plot for sequential mf-bnn\n",
    "ax.plot(\n",
    "    test_samples.numpy(),\n",
    "    np.abs(test_hf_responses_noiseless.numpy() - sequential_bnn_y),\n",
    "    \"-\",\n",
    "    color=\"#0077BB\",\n",
    "    linewidth=2,\n",
    "    label=\"Meng's MF-BNN\",\n",
    ")\n",
    "ax.plot(\n",
    "    test_samples.numpy(),\n",
    "    np.abs(test_hf_responses_noiseless.numpy() - y_proposed),\n",
    "    \"-\",\n",
    "    color=\"#EE7733\",\n",
    "    linewidth=2,\n",
    "    label=\"MF-DNN-BNN\",\n",
    ")\n",
    "ax.set_xlabel(\"x\", fontsize=font_size)\n",
    "ax.set_ylabel(\"Absolute error\", fontsize=font_size)\n",
    "ax.tick_params(labelsize=font_size)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise_error.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise_error.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"mf_dnn_bnn_known_noise_error.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfpml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
